{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP6NJCujJUh3KASYgf0M7O1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","# Define CNN Model\n","class DeepFakeCNN(nn.Module):\n","    def __init__(self, input_size=128):  # Default input size 128x128\n","        super(DeepFakeCNN, self).__init__()\n","\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: input_size/2\n","\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: input_size/4\n","\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: input_size/8\n","\n","            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)   # Output: input_size/16\n","        )\n","\n","        # Dynamically calculate flattened size\n","        self._to_linear = None\n","        self._get_conv_output(input_size)\n","\n","        # Fully connected layers\n","        self.fc_layers = nn.Sequential(\n","            nn.Linear(self._to_linear, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","\n","            nn.Linear(512, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","\n","            nn.Linear(128, 2)  # Binary Classification (Real vs Deepfake)\n","        )\n","\n","    def _get_conv_output(self, input_size):\n","        \"\"\" Function to calculate the output size after conv layers \"\"\"\n","        with torch.no_grad():\n","            dummy_input = torch.zeros(1, 3, input_size, input_size)\n","            output = self.conv_layers(dummy_input)\n","            self._to_linear = output.view(1, -1).size(1)\n","\n","    def forward(self, x):\n","        x = self.conv_layers(x)\n","        x = x.view(x.size(0), -1)  # Flatten\n","        x = self.fc_layers(x)\n","        return x\n","\n","# Define device (Use GPU if available)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define input size\n","input_size = 224  # Make sure input images match this size\n","\n","# Initialize Model\n","model = DeepFakeCNN(input_size).to(device)\n","\n","# Load Weights\n","model.load_state_dict(torch.load(\"/content/deepfake_cnn.pth\", map_location=device))\n","model.eval()  # Set model to evaluation mode\n","\n","print(\"Model loaded successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SWfxJe8upgQF","executionInfo":{"status":"ok","timestamp":1743633625006,"user_tz":-330,"elapsed":1100,"user":{"displayName":"MISHRA VIVEK CHANDRESH","userId":"14194337171619277071"}},"outputId":"ee533f09-5838-40fc-f505-a03b4227fede"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded successfully!\n"]}]},{"cell_type":"code","source":["from PIL import Image\n","import torch\n","import torchvision.transforms as transforms\n","\n","# Define the transformation\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Lambda(lambda x: x.expand(3, -1, -1) if x.shape[0] == 1 else x),  # Convert grayscale to 3-channel\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Adjust normalization values if needed\n","])\n","\n","# Load and preprocess the image\n","image_path = \"/content/ChatGPT Image Apr 3, 2025, 04_17_36 AM.png\"  # Update with your image path\n","image = Image.open(image_path).convert(\"RGB\")  # Convert grayscale to RGB\n","image = transform(image).unsqueeze(0)  # Add batch dimension\n","\n","print(image.shape)  # Should be [1, 3, 224, 224]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9rOpNl3jso_I","executionInfo":{"status":"ok","timestamp":1743634326904,"user_tz":-330,"elapsed":59,"user":{"displayName":"MISHRA VIVEK CHANDRESH","userId":"14194337171619277071"}},"outputId":"4caf2912-1873-4b24-9993-d9c7e61347a1"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 3, 224, 224])\n"]}]},{"cell_type":"code","source":["# Move image to the same device as the model\n","image = image.to(device)\n","\n","# Set model to evaluation mode\n","model.eval()\n","\n","# Run inference\n","with torch.no_grad():\n","    output = model(image)\n","    prediction = torch.argmax(output, dim=1).item()\n","\n","# Interpret the result\n","if prediction == 0:\n","    print(\"Prediction: Real Image ðŸŸ¢\")\n","else:\n","    print(\"Prediction: Deepfake Image ðŸ”´\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5e9OCHPeqxpb","executionInfo":{"status":"ok","timestamp":1743634328105,"user_tz":-330,"elapsed":44,"user":{"displayName":"MISHRA VIVEK CHANDRESH","userId":"14194337171619277071"}},"outputId":"7b53b2b6-4079-4871-f36c-bdfeeebee57b"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction: Real Image ðŸŸ¢\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Iq_IX_qXq21C"},"execution_count":null,"outputs":[]}]}